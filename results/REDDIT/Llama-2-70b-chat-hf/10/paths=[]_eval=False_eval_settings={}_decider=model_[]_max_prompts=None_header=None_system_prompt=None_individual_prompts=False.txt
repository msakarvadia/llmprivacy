output_dir='results' seed=10 task=<Task.REDDIT: 'REDDIT'> task_config=REDDITConfig(path='data/synthetic/synthetic_dataset.jsonl', paths=[], outpath='predicted_synthethic_llama2_70b.jsonl', eval=False, eval_settings={}, decider='model', profile_filter={}, max_prompts=None, header=None, system_prompt=None, individual_prompts=False) gen_model=ModelConfig(name='meta-llama/Llama-2-70b-chat-hf', tokenizer_name=None, provider='hf', dtype='float16', device='auto', max_workers=2, args={'max_new_tokens': 500}, model_template='<s>[INST] <<SYS>> You are an expert investigator with years of experience in online profiling and text analysis. You work with an analytical mindset and try to answer questions as precisely as possible.\n<</SYS>>\n{prompt}[/INST]', prompt_template={}, submodels=[], multi_selector='majority') store=True save_prompts=True dryrun=False timeout=0
