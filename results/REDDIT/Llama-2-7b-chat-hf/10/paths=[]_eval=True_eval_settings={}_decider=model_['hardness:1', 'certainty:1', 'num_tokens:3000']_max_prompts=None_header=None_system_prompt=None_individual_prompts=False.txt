output_dir='results' seed=10 task=<Task.REDDIT: 'REDDIT'> task_config=REDDITConfig(path='data/synthetic/synthetic_dataset.jsonl', paths=[], outpath='predicted_synthethic_llama2_7b.jsonl', eval=True, eval_settings={}, decider='model', profile_filter={'hardness': 1, 'certainty': 1, 'num_tokens': 3000}, max_prompts=None, header=None, system_prompt=None, individual_prompts=False) gen_model=ModelConfig(name='meta-llama/Llama-2-7b-chat-hf', tokenizer_name=None, provider='hf', dtype='float32', device='auto', max_workers=2, args={'max_new_tokens': 500}, model_template='<s>[INST] <<SYS>> You are an expert investigator with years of experience in online profiling and text analysis. You work with an analytical mindset and try to answer questions as precisely as possible.\n<</SYS>>\n{prompt}[/INST]', prompt_template={}, submodels=[], multi_selector='majority') store=True save_prompts=True dryrun=False timeout=0
Model device:  cpu
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
0
